# -*- coding: utf-8 -*-
"""Bank Customer Churan Predicition.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nfsM-liYFv-1Y_83lhBMQa-t0ltbvVky
"""



"""# **Bank Customer Churn Prediciton**

## Steps involved
### Importing the Libraries
### Loading the Dataset
### EDA
### Feature Engineering
### Model Building
### Model Evaluation and Selection:
### Prediction
### Deploying the Model

"""

#connecting drive to colab
from google.colab import drive
drive.mount('/content/drive')

"""# Importing libraries"""

#importing the required libraries

import os
import numpy as np
import pandas as pd
import plotly as pl
import seaborn as sns
import matplotlib.pyplot as plt

"""# Loading the Dataset"""

#loading the dataset
churn = pd.read_csv("/content/drive/MyDrive/Churn_Modelling.csv")
#Displaying the top 5 rows
churn.head()

#Displaying below 5 rows
churn.tail()

#finding the shape of the dataset
churn.shape

"""# Exploratory Data Analysis (EDA)"""

#listing the columns from the dataset
churn.columns

#Getting information about the dataset
churn.info

#Checking the null values in the dataset
churn.isnull().sum()

#Getting the statistical information from the dataset
churn.describe()

#Getting the statistical information from the dataset
churn.describe(include="all")

#dopping the columns
churn = churn.drop(['RowNumber', 'CustomerId', 'Surname'],axis=1)

churn.head()

"""# Feature Selection"""

#Encoding the categorial data
churn['Geography'].unique()



churn = pd.get_dummies(churn,drop_first=True)
churn.head()

#handling the imbalanced data
churn["Exited"].value_counts()

# Count the occurrences of each unique value in the 'Exited' column
exited_counts = churn['Exited'].value_counts()

# Create a bar plot
plt.figure(figsize=(8, 6))
plt.bar(exited_counts.index, exited_counts.values, color=['blue', 'orange'])

# Add titles and labels
plt.title('Count of Exited')
plt.xlabel('Exited')
plt.ylabel('Count')
plt.xticks(exited_counts.index)

# Show the plot
plt.show()

"""# Model Building"""

#importing the Sklearn libraries for modeling
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score,recall_score,f1_score
from sklearn import metrics
from sklearn.metrics import confusion_matrix, classification_report
from sklearn import svm
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier

X = churn.drop('Exited',axis=1)
y = churn['Exited']

from imblearn.over_sampling import SMOTE

# Assuming X and y are your feature matrix and target vector
X_res, y_res = SMOTE().fit_resample(X, y)

y_res.value_counts()

#spliting the data into train, test split
X_train,X_test,y_train,y_test=train_test_split(X_res,y_res,test_size=0.20,random_state=42)
#getting the shape of the train test split
X_train.shape,X_test.shape,y_train.shape,y_test.shape

#Feature scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

X_train



"""# Logistic Regression"""

#logistic regression
log_reg = LogisticRegression()
log_reg.fit(X_train,y_train)

y_pred1 = log_reg.predict(X_test)

accuracy_score(y_test,y_pred1)

accuracy_score(y_test,y_pred1)

f1_score(y_test,y_pred1)

precision_score(y_test,y_pred1)

recall_score(y_test,y_pred1)



"""# Support Vector classifier"""

#Support Vector classifier
svm = svm.SVC()
svm.fit(X_train,y_train)
y_pred = svm.predict(X_test)
print(confusion_matrix(y_test,y_pred))
print(classification_report(y_test,y_pred))
print(accuracy_score(y_test,y_pred))



"""# KNN Classifier"""

#KNN classifier
knn = KNeighborsClassifier()
knn.fit(X_train,y_train)
y_pred2 = knn.predict(X_test)

print(accuracy_score(y_test,y_pred2))
print(f1_score(y_test,y_pred2))
print(precision_score(y_test,y_pred2))
print(recall_score(y_test,y_pred2))



"""#Decision Tree Classifier

"""

#Decision Tree Classifier
dtc = DecisionTreeClassifier()
dtc.fit(X_train,y_train)
y_pred3 = dtc.predict(X_test)

print(accuracy_score(y_test,y_pred3))
print(f1_score(y_test,y_pred3))
print(precision_score(y_test,y_pred3))
print(recall_score(y_test,y_pred3))





"""#Random Forest Classifier

"""

#Random Forest Classifier
rfc = RandomForestClassifier()
rfc.fit(X_train,y_train)
y_pred4 = rfc.predict(X_test)

print(accuracy_score(y_test,y_pred4))
print(f1_score(y_test,y_pred4))
print(precision_score(y_test,y_pred4))
print(recall_score(y_test,y_pred4))



"""#Gradoent Boostong Classifier

"""

#Gradoent Boostong Classifier
gbc = GradientBoostingClassifier()
gbc.fit(X_train,y_train)
y_pred5 = gbc.predict(X_test)

print(accuracy_score(y_test,y_pred5))
print(f1_score(y_test,y_pred5))
print(precision_score(y_test,y_pred5))
print(recall_score(y_test,y_pred5))

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

final_data=pd.DataFrame({'Models':['LR','SVC','KNN','DT','RF','GBC'],
                        'ACC':[accuracy_score(y_test,y_pred1),
                              accuracy_score(y_test,y_pred2),
                              accuracy_score(y_test,y_pred3),
                              accuracy_score(y_test,y_pred4),
                              accuracy_score(y_test,y_pred5),
                              accuracy_score(y_test,y_pred)]})

final_data

# Assuming final_data is your DataFrame and 'Models' and 'ACC' are your columns
sns.barplot(x='Models', y='ACC', data=final_data)
plt.xticks(rotation=90)
plt.show()

final_data=pd.DataFrame({'Models':['LR','SVC','KNN','DT','RF','GBC'],
                        'PRE':[precision_score(y_test,y_pred1),
                              precision_score(y_test,y_pred2),
                              precision_score(y_test,y_pred3),
                              precision_score(y_test,y_pred4),
                              precision_score(y_test,y_pred5),
                              precision_score(y_test,y_pred)]})

final_data

sns.barplot(x='Models', y='PRE', data=final_data)
plt.xticks(rotation=90)
plt.show()



"""#Save the model

"""

#Save the model
X_res=sc.fit_transform(X_res)
rfc.fit(X_res,y_res)

import joblib
joblib.dump(rfc,'churn_predict_model')

model = joblib.load('churn_predict_model')
churn.columns

model.predict([[619,42,2,0.0,0,0,0,101348.88,0,0,0]])

# Save the model and the scaler
import pickle

with open('rf_churn_model.pkl', 'wb') as file:
    pickle.dump(rfc, file)

with open('scaler_churn.pkl', 'wb') as file:
    pickle.dump(scaler, file)



#GUI
from tkinter import *
from sklearn.preprocessing import StandardScaler
import joblib

def show_entry_fields():
    try:
        p1 = int(e1.get())
        p2 = int(e2.get())
        p3 = int(e3.get())
        p4 = float(e4.get())
        p5 = int(e5.get())
        p6 = int(e6.get())
        p7 = int(e7.get())
        p8 = float(e8.get())
        p9 = int(e9.get())
        p10 = int(e10.get())

        if p9 == 1:
            Geography_Germany = 1
            Geography_Spain = 0
            Geography_France = 0
        elif p9 == 2:
            Geography_Germany = 0
            Geography_Spain = 1
            Geography_France = 0
        elif p9 == 3:
            Geography_Germany = 0
            Geography_Spain = 0
            Geography_France = 1
        else:
            raise ValueError("Invalid value for Geography")

        # Load the model
        model = joblib.load('churn_model.pkl')
        # Assuming 'sc' is the StandardScaler instance used during training
        sc = joblib.load('scaler.pkl')

        # Predict the result
        result = model.predict(sc.transform([[p1, p2, p3, p4, p5, p6, p7, p8, Geography_Germany, Geography_Spain, Geography_France, p10]]))

        # Display the result
        if result == 0:
            result_label.config(text="No Exit")
        else:
            result_label.config(text="Exit")
    except ValueError as ve:
        result_label.config(text=f"Error: {ve}")
    except Exception as e:
        result_label.config(text=f"Unexpected error: {e}")

# Create the main window
master = Tk()
master.title("Bank Customers Churn Prediction Using Machine Learning")

# Create and place the labels and entry widgets
Label(master, text="Customers Churn Prediction Using ML", bg="black", fg="white").grid(row=0, columnspan=2)
labels = ["CreditScore", "Age", "Tenure", "Balance", "NumOfProducts", "HasCrCard", "IsActiveMember", "EstimatedSalary", "Geography (1: Germany, 2: Spain, 3: France)", "Gender (1: Male, 0: Female)"]
entries = []

for idx, text in enumerate(labels, start=1):
    Label(master, text=text).grid(row=idx)
    entry = Entry(master)
    entry.grid(row=idx, column=1)
    entries.append(entry)

e1, e2, e3, e4, e5, e6, e7, e8, e9, e10 = entries

# Create and place the Predict button
Button(master, text='Predict', command=show_entry_fields).grid(row=len(labels)+1, columnspan=2)

# Create and place the result label
result_label = Label(master, text="")
result_label.grid(row=len(labels)+2, columnspan=2)

# Start the main loop
mainloop()

# Load the model
model = joblib.load('churn_model.pkl')
# Assuming 'sc' is the StandardScaler instance used during training
sc = joblib.load('scaler.pkl')

import joblib
from sklearn.preprocessing import StandardScaler

def get_user_input():
    try:
        p1 = int(input("Enter CreditScore: "))
        p2 = int(input("Enter Age: "))
        p3 = int(input("Enter Tenure: "))
        p4 = float(input("Enter Balance: "))
        p5 = int(input("Enter NumOfProducts: "))
        p6 = int(input("Enter HasCrCard (1: Yes, 0: No): "))
        p7 = int(input("Enter IsActiveMember (1: Yes, 0: No): "))
        p8 = float(input("Enter EstimatedSalary: "))
        p9 = int(input("Enter Geography (1: Germany, 2: Spain, 3: France): "))
        p10 = int(input("Enter Gender (1: Male, 0: Female): "))

        if p9 == 1:
            Geography_Germany = 1
            Geography_Spain = 0
            Geography_France = 0
        elif p9 == 2:
            Geography_Germany = 0
            Geography_Spain = 1
            Geography_France = 0
        elif p9 == 3:
            Geography_Germany = 0
            Geography_Spain = 0
            Geography_France = 1
        else:
            raise ValueError("Invalid value for Geography")

        # Load the model
        model = joblib.load('churn_model.pkl')
        # Assuming 'sc' is the StandardScaler instance used during training
        sc = joblib.load('scaler.pkl')

        # Predict the result
        result = model.predict(sc.transform([[p1, p2, p3, p4, p5, p6, p7, p8, Geography_Germany, Geography_Spain, Geography_France, p10]]))

        # Display the result
        if result == 0:
            print("No Exit")
        else:
            print("Exit")
    except ValueError as ve:
        print(f"Error: {ve}")
    except Exception as e:
        print(f"Unexpected error: {e}")

# Run the function to get user input and display the result
get_user_input()

#pip install streamlit

import pickle

# Example: Save the model and scaler
with open('churn_model.pkl', 'wb') as model_file:
    pickle.dump(model, model_file)

with open('scaler.pkl', 'wb') as scaler_file:
    pickle.dump("churn_model.pkl", scaler_file)

"""# Deploying the Model"""

import joblib
import streamlit as st
from sklearn.preprocessing import StandardScaler

# Load the model and scaler outside the function to avoid reloading them multiple times
model = joblib.load('rf_churn_model.pkl')
sc = joblib.load('scaler_churn.pkl')

def predict_churn(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10):
    if p9 == 1:
        Geography_Germany = 1
        Geography_Spain = 0
        Geography_France = 0
    elif p9 == 2:
        Geography_Germany = 0
        Geography_Spain = 1
        Geography_France = 0
    elif p9 == 3:
        Geography_Germany = 0
        Geography_Spain = 0
        Geography_France = 1
    else:
        raise ValueError("Invalid value for Geography")

    result = model.predict(sc.transform([[p1, p2, p3, p4, p5, p6, p7, p8, Geography_Germany, Geography_Spain, Geography_France, p10]]))
    return result[0]

st.title("Bank Customers Churn Prediction Using Machine Learning")

# Get user input
p1 = st.number_input("CreditScore", min_value=0, max_value=1000, value=650)
p2 = st.number_input("Age", min_value=0, max_value=120, value=35)
p3 = st.number_input("Tenure", min_value=0, max_value=10, value=5)
p4 = st.number_input("Balance", min_value=0.0, value=10000.0)
p5 = st.number_input("NumOfProducts", min_value=1, max_value=4, value=1)
p6 = st.selectbox("HasCrCard (1: Yes, 0: No)", options=[0, 1])
p7 = st.selectbox("IsActiveMember (1: Yes, 0: No)", options=[0, 1])
p8 = st.number_input("EstimatedSalary", min_value=0.0, value=50000.0)
p9 = st.selectbox("Geography", options=[1, 2, 3], format_func=lambda x: ["Germany", "Spain", "France"][x-1])
p10 = st.selectbox("Gender (1: Male, 0: Female)", options=[0, 1])

if st.button("Predict"):
    try:
        result = predict_churn(p1, p2, p3, p4, p5, p6, p7, p8, p9, p10)
        if result == 0:
            st.success("No Exit")
        else:
            st.warning("Exit")
    except ValueError as ve:
        st.error(f"Error: {ve}")
    except Exception as e:
        st.error(f"Unexpected error: {e}")

